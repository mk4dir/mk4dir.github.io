[{"content":"Data Volumes Docker Volumes are created and assigned when containers are started. Data Volumes allow you to map a host directory to a container for sharing data.\nThis mapping is bi-directional. It allows data stored on the host to be accessed from within the container. It also means data saved by the process inside the container is persisted on the host.\nTask This example will use Redis as a way to persist data. Start a Redis container below, and create a data volume using the -v parameter. This specifies that any data saved inside the container to the /data directory should be persisted on the host in the directory /docker/redis-data.\ndocker run -v /docker/redis-data:/data \\  --name r1 -d redis \\  redis-server --appendonly yes Create a file called data with the follwing content:\nSET counter 42 INFO server SAVE QUIT We can pipe data into the Redis instance using the following command.\ncat data | docker exec -i r1 redis-cli --pipe\nRedis will save this data to disk. Check:\ndocker exec -i r1 redis-cli GET counter\nOn the host we can investigate the mapped direct which should contain the Redis data file.\nls -lah /docker/redis-data\nThis same directory can be mounted to a second container. One usage is to have a Docker Container performing backup operations on your data.\ndocker run -v /docker/redis-data:/backup ubuntu ls /backup\nShared Volumes Data Volumes mapped to the host are great for persisting data. However, to gain access to them from another container you need to know the exact path which can make it error-prone.\nAn alternate approach is to use -volumes-from. The parameter maps the mapped volumes from the source container to the container being launched.\nIn this case, we\u0026rsquo;re mapping our Redis container\u0026rsquo;s volume to an Ubuntu container. The /data directory only exists within our Redis container, however, because of -volumes-from our Ubuntu container can access the data.\ndocker run --volumes-from r1 -it ubuntu ls /data\nThis allows us to access volumes from other containers without having to be concerned how they\u0026rsquo;re persisted on the host.\nRead-only Volumes Mounting Volumes gives the container full read and write access to the directory. You can specify read-only permissions on the directory by adding the permissions :ro to the mount.\nIf the container attempts to modify data within the directory it will error.\ndocker run -v /docker/redis-data:/data:ro -it ubuntu rm -rf /data\n","permalink":"https://kadirkarakoc.com/posts/docker-notes/dn11/","summary":"Data Volumes Docker Volumes are created and assigned when containers are started. Data Volumes allow you to map a host directory to a container for sharing data.\nThis mapping is bi-directional. It allows data stored on the host to be accessed from within the container. It also means data saved by the process inside the container is persisted on the host.\nTask This example will use Redis as a way to persist data.","title":"Docker[11] | Persisting Data Using Volumes"},{"content":"Running a basic web server Run a container if nginx image. docker run -d -P --name myweb nginx\nYou can find ports exposed by container in docker ps. Check PORTS column.\nAlso you can see web running in container using curl localhost:$(docker inspect myweb -f '{{(index (index .NetworkSettings.Ports \u0026quot;80/tcp\u0026quot;) 0).HostPort}}')\nAlternatively you can use docker port myweb 80 to get the exposed ports.\nPort can be manually exposed using -p flag. docker run -d -p 8080:80 --name myweb1 nginx\nAbove command will start a container from image nginx with internal port 80 exposed to external port 8080.\nLocating an IP address You can get the IP address of running container using docker inspect --format '{{ .NetworkSettings.IPAddress }}' myweb1\nCheck connectivity You can check network connectivity to container IP using ping $(docker inspect --format '{{ .NetworkSettings.IPAddress }}' myweb1)\nBridge networking It is a default networking mode if you don\u0026rsquo;t specify networking mode explicitly using --net option.\nIt creates MASQUERADE and DNAT iptables rules for outbound and inbound traffic respectively.\nCheck iptables rules for our container using iptables -t nat -L | grep $(docker inspect --format '{{ .NetworkSettings.IPAddress }}' myweb1)\nGet bridge details using docker inspect myweb1 -f '{{json .NetworkSettings.Networks}}'\nNull driver This mode creates network isolation for container. A container can\u0026rsquo;t send and receive network traffic. It can only see lo interface.\nYou can used this mode like docker run -d --net none --name nullnetdemo nginx.\nEven though it is a container running web server, you can\u0026rsquo;t connect to it.\nCheck network details using docker inspect nullnetdemo -f '{{json .NetworkSettings.Networks}}'\nIt shows none in networks.\nHost driver When using this driver, container shares network with host. It can be used using \u0026ndash;net host option.\nYou can create one like docker run -d -p 8080:80 \u0026ndash;net host \u0026ndash;name hostnetdemo nginx.\nIt can be easily checked using docker inspect hostnetdemo -f \u0026lsquo;{{json .NetworkSettings.Networks}}\u0026rsquo;\nContainer driver This driver is used to re-use network stack of another container.\nIt can be used using --net container:id option.\nCreate first container using docker run -d --name maincontainer nginx\nSpawn second container using docker run --net container:maincontainer --name secondarycontainer -d busybox sh -c \u0026quot;while true; do $(echo date); sleep 1; done\u0026quot;\nOur secondarycontainer will reuse the network stack of first container. We can access nginx running at port 80 using localhost.\ndocker exec -it secondarycontainer sh\nwget localhost cat index.html\nYou can see content of downloaded index.html page from nginx.\n","permalink":"https://kadirkarakoc.com/posts/docker-notes/dn10/","summary":"Running a basic web server Run a container if nginx image. docker run -d -P --name myweb nginx\nYou can find ports exposed by container in docker ps. Check PORTS column.\nAlso you can see web running in container using curl localhost:$(docker inspect myweb -f '{{(index (index .NetworkSettings.Ports \u0026quot;80/tcp\u0026quot;) 0).HostPort}}')\nAlternatively you can use docker port myweb 80 to get the exposed ports.\nPort can be manually exposed using -p flag.","title":"Docker[10] | Networking Fundamentals"},{"content":"Docker Logs When you start a container, Docker will track the Standard Out and Standard Error outputs from the process and make them available via the client.\nExample In the background, there is an instance of Redis running with the name redis-server. Using the Docker client, we can access the standard out and standard error outputs using docker logs redis-server\nSysLog By default, the Docker logs are outputting using the json-file logger meaning the output stored in a JSON file on the host. This can result in large files filling the disk. As a result, you can change the log driver to move to a different destination.\nSyslog The Syslog log driver will write all the container logs to the central syslog on the host. \u0026ldquo;syslog is a widely used standard for message logging. It permits separation of the software that generates messages, the system that stores them, and the software that reports and analyses them.\u0026rdquo; Wikipedia\nThis log-driver is designed to be used when syslog is being collected and aggregated by an external system.\nExample The command below will redirect the redis logs to syslog.\ndocker run -d --name redis-syslog --log-driver=syslog redis\nAccessing Logs If you attempted to view the logs using the client you\u0026rsquo;ll recieve the error FATA[0000] \u0026ldquo;logs\u0026rdquo; command is supported only for \u0026ldquo;json-file\u0026rdquo; logging driver\nInstead, you need to access them via the syslog stream.\nDisable Logging The third option is to disable logging on the container. This is particularly useful for containers which are very verbose in their logging.\nExample When the container is launched simply set the log-driver to none. No output will be logged.\ndocker run -d --name redis-none --log-driver=none redis\nWhich Config? The inspect command allows you to identify the logging configuration for a particular container. The command below will output the LogConfig section for each of the containers.\nServer created in step 1\ndocker inspect --format '{{ .HostConfig.LogConfig }}' redis-server\nServer created in step 2\ndocker inspect --format '{{ .HostConfig.LogConfig }}' redis-syslog\nServer created in this step\ndocker inspect --format '{{ .HostConfig.LogConfig }}' redis-none\n","permalink":"https://kadirkarakoc.com/posts/docker-notes/dn9/","summary":"Docker Logs When you start a container, Docker will track the Standard Out and Standard Error outputs from the process and make them available via the client.\nExample In the background, there is an instance of Redis running with the name redis-server. Using the Docker client, we can access the standard out and standard error outputs using docker logs redis-server\nSysLog By default, the Docker logs are outputting using the json-file logger meaning the output stored in a JSON file on the host.","title":"Docker[9] | Managing Log Files"},{"content":"Name a container So far we have referenced containers only with their ID or with a prefix, but containers can also be referenced by their names also.\nCreate a new container with name counter from image loodse/counter using docker run -d -it --name counter loodse/counter.\nNow the container with name counter is started, you can perform various operations on containers by using its name.\nCheck the logs using docker logs counter.\nInspecting a container There are many configurations and details associated with each running container like IP Address, Mac Address, Ports exposed, Creation timestamp and many others.\nYou can retrieve these details using command docker inspect counter.\nUsing \u0026ndash;format docker inspect command outputs lot of details in parsable json. You can get particular fields from that.\ndocker inspect -f '{{json .Created}}' counter. This way you can directly retrieve Created field from json output.\n","permalink":"https://kadirkarakoc.com/posts/docker-notes/dn8/","summary":"Name a container So far we have referenced containers only with their ID or with a prefix, but containers can also be referenced by their names also.\nCreate a new container with name counter from image loodse/counter using docker run -d -it --name counter loodse/counter.\nNow the container with name counter is started, you can perform various operations on containers by using its name.\nCheck the logs using docker logs counter.","title":"Docker[8] | Naming And Inspecting"},{"content":"Docker Ignore To prevent sensitive files or directories from being included by mistake in images, you can add a file named .dockerignore.\nExample A Dockerfile copies the working directory into the Docker Image. As a result, this would include potentially sensitive information such as a passwords file which we\u0026rsquo;d want to manage outside the image. View the Dockerfile with\ncd ~/scrapbook/tutorial cat Dockerfile\nBuild the image with docker build -t password . \nLook at the output using docker run password ls /app\nThis will include the passwords file.\nIgnore File The following command would include passwords.txt in our .dockerignore file and ensure that it didn\u0026rsquo;t accidentally end up in a container. The .dockerignore file would be stored in source control and share with the team to ensure that everyone is consistent.\necho passwords.txt \u0026gt;\u0026gt; .dockerignore\nThe ignore file supports directories and Regular expressions to define the restrictions, very similar to .gitignore. This file can also be used to improve build times which we\u0026rsquo;ll investigate in the next step.\nBuild the image, because of the Docker Ignore file it shouldn\u0026rsquo;t include the passwords file.\ndocker build -t nopassword . \nLook at the output using\ndocker run nopassword ls /app\nDocker Build Context The .dockerignore file can ensure that sensitive details are not included in a Docker Image. However they can also be used to improve the build time of images.\nIn the environment, a hypothetical 100M temporary file has been created. This file is never used by the Dockerfile. When you execute a build command, Docker sends the entire path contents to the Engine for it to calculate which files to include. As a result sending the 100M file is unrequired and creates a slower build.\nYou can see the 100M impact by executing following the command.\ndocker build -t large-file-context .\nIn the next step, we\u0026rsquo;ll demonstrate how to improve the performance of the build.\nProtip It\u0026rsquo;s wise to ignore .git directories along with dependencies that are downloaded/built within the image such as node_modules. These are never used by the application running within the Docker Container and just add overhead to the build process.\nOptimised Build In the same way, we used the .dockerignore file to exclude sensitive files, we can use it to exclude files which we don\u0026rsquo;t want to be sent to the Docker Build Context during the build.\nOptimizing To speed up our build, simply include the filename of the large file in the ignore file.\necho somelargefile.img \u0026gt;\u0026gt; .dockerignore\nWhen we rebuild the image, it will be much faster as it doesn\u0026rsquo;t have to copy the large file.\ndocker build -t no-large-file-context . \nThis optimisation has a greater impact when ignoring large directories such as .git.\n","permalink":"https://kadirkarakoc.com/posts/docker-notes/dn7/","summary":"Docker Ignore To prevent sensitive files or directories from being included by mistake in images, you can add a file named .dockerignore.\nExample A Dockerfile copies the working directory into the Docker Image. As a result, this would include potentially sensitive information such as a passwords file which we\u0026rsquo;d want to manage outside the image. View the Dockerfile with\ncd ~/scrapbook/tutorial cat Dockerfile\nBuild the image with docker build -t password .","title":"Docker[7] | Docker Build ignore Files"},{"content":"Building Images with Dockerfile Docker can build images automatically by reading the instructions from a Dockerfile, a text file containing all the commands, in order, needed to build a given image. Dockerfiles adhere to a specific format and use a specific set of instructions.\nWrite Dockerfile In this step we shall create Dockerfile.\nCreate a Dockerfile with following content in current directory.\ncat \u0026gt; Dockerfile \u0026lt;\u0026lt; EOF FROM ubuntu:18.04 RUN apt-get update \u0026amp;\u0026amp; apt-get install apache2 -y \u0026amp;\u0026amp; apt-get clean CMD [\u0026#34;apache2ctl\u0026#34;, \u0026#34;-DFOREGROUND\u0026#34;] EOF Verify the file: cat Dockerfile\nAbove Dockerfile content describes a Debian jessie Docker image with Apache web server installed.\nFROM indicates the base image for our build Each RUN line will be executed by Docker during the build Our RUN commands must be non-interactive. (You can‘t provide input to Docker during the build.) In many cases, we will add the -y flag to apt-get.\nBuild it ! We can build a docker image by executing docker build -t webserver.\nThe docker build command builds an image from a Dockerfile and a context. The build’s context is the files at a specified location PATH or URL. The PATH is a directory on your local filesystem. The URL is a Git repository location.\nThe Docker daemon runs the instructions in the Dockerfile one-by-one, committing the result of each instruction to a new image if necessary, before finally outputting the ID of your new image.\nView the stored images on your host:\ndocker images\nRun an Image Now we have an image created from Dockerfile, we\u0026rsquo;ll run it.\ndocker run -d -p 8080:80 --name www webserver\nVerify the output with curl:\ncurl localhost:8080\nBuild a webapp image We need to create a index.html file in html directory with following content.\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;This is a title\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Hello world!\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Enhance our existing Dockerfile with following content.\ncat \u0026gt; Dockerfile \u0026lt;\u0026lt; EOF FROM ubuntu:18.04 RUN apt-get update \u0026amp;\u0026amp; apt-get install apache2 -y \u0026amp;\u0026amp; apt-get clean COPY html /var/www/html CMD [\u0026#34;apache2ctl\u0026#34;, \u0026#34;-DFOREGROUND\u0026#34;] EOF Verify the Dockerfile: cat Dockerfile Verify the html file: cat html/index.html\nThe COPY instruction copies new files or directories from and adds them to the filesystem of the container at the path .\nBuild and Run it Again docker build -t webserver.\ndocker run -d -p 8090:80 --name www1 webserver\nVerify the updated output with curl:\ncurl localhost:8090\nTry it yourself Change the following things:\n Web content should contain Docker is awesome! Dockerfile should an ENTRYPOINT with the default argument -DFOREGROUND  Validate docker run -it -p 80:80 -n my-web my-image` # interactive shell in the container # verify hostname and envrionment is the id of the conainer hostname env df #check if apache is running ps -aufx Open second terminal\nVerify if you get your HTML text Docker is awesome!:\ncurl localhost:80\n","permalink":"https://kadirkarakoc.com/posts/docker-notes/dn6/","summary":"Building Images with Dockerfile Docker can build images automatically by reading the instructions from a Dockerfile, a text file containing all the commands, in order, needed to build a given image. Dockerfiles adhere to a specific format and use a specific set of instructions.\nWrite Dockerfile In this step we shall create Dockerfile.\nCreate a Dockerfile with following content in current directory.\ncat \u0026gt; Dockerfile \u0026lt;\u0026lt; EOF FROM ubuntu:18.04 RUN apt-get update \u0026amp;\u0026amp; apt-get install apache2 -y \u0026amp;\u0026amp; apt-get clean CMD [\u0026#34;apache2ctl\u0026#34;, \u0026#34;-DFOREGROUND\u0026#34;] EOF Verify the file: cat Dockerfile","title":"Docker[6] | Building Images with Dockerfile"},{"content":"Install Apache into running container docker commit command creates an image from container\u0026rsquo;s changes.\nStart an Debian container:\ndocker run -it debian. It will pull debian image to your local system if it does not exist already.\nAfter pulling image, it will start container and open a shell into running container.\nWe\u0026rsquo;ll install Apache into running container. apt-get update \u0026amp;\u0026amp; apt-get install apache2 -y\nexit\nInspect the changes You can get the ID of container using docker ps -a. Check the first entry with image name as debian.\nWe can inspect changes to files and directories on a container\u0026rsquo;s filesystem using docker diff \u0026lt;yourContainerId\u0026gt;.\nThis show the list of added, changed or deleted with capital A, C or D respectively prefixed with each file.\nCreate image using docker commit You can create a new image from changes using following command. docker commit \u0026lt;yourContainerId\u0026gt;\nRun the image using docker run -it \u0026lt;newImageId\u0026gt;.\nTag your image You can tag your newly created image using docker tag \u0026lt;newImageId\u0026gt; webserver.\nYou can get id of image you want to tag using docker images | grep debian.\nAfter tagging the image, you can run it with a tag. docker run -it webserver\n","permalink":"https://kadirkarakoc.com/posts/docker-notes/dn5/","summary":"Install Apache into running container docker commit command creates an image from container\u0026rsquo;s changes.\nStart an Debian container:\ndocker run -it debian. It will pull debian image to your local system if it does not exist already.\nAfter pulling image, it will start container and open a shell into running container.\nWe\u0026rsquo;ll install Apache into running container. apt-get update \u0026amp;\u0026amp; apt-get install apache2 -y\nexit\nInspect the changes You can get the ID of container using docker ps -a.","title":"Docker[5] | Building Images Interactively"},{"content":"Layers in docker image Each Docker image references a list of read-only layers that represent filesystem differences.\nLayers are stacked on top of each other to form a base for a container\u0026rsquo;s root filesystem.\nPull debian image to your local system. docker pull debian.\ndocker history debian shows you list of layers that debian image contains.\nMore Information you can find out with: docker inspect debian\nInspect the layers More Information about an image you can find out with: docker inspect debian\nThere you will also see how the image is build and e.g. which command will executed at the container startup.\ndocker inspect debian | grep Cmd --after-context=10\nOr what user\ndocker inspect debian | grep User --before-context=5\nWhat\u0026rsquo;s about the sha of the image.\ndocker inspect debian | grep Id\nYou can also use these to run the container:\ndocker run -it sha256:0af60a5c6dd017d7023f6b6c71f3ffbb9beb2948d842bcb1ba36d597fb96e75a\n","permalink":"https://kadirkarakoc.com/posts/docker-notes/dn4/","summary":"Layers in docker image Each Docker image references a list of read-only layers that represent filesystem differences.\nLayers are stacked on top of each other to form a base for a container\u0026rsquo;s root filesystem.\nPull debian image to your local system. docker pull debian.\ndocker history debian shows you list of layers that debian image contains.\nMore Information you can find out with: docker inspect debian\nInspect the layers More Information about an image you can find out with: docker inspect debian","title":"Docker[4] | Docker Images And Layers"},{"content":"Run container in foreground In foreground mode (by default when -d is not specified), docker run can start the process in the container and attach the console to the process' standard input, output, and standard error. It can even pretend to be a TTY (this is what most command line executables expect) and pass along signals. docker run -t -p 80:80 loodse/demo-www To stop it, press ^C.\nDetached container To start a container in detached mode, use -d=true or just -d option. By design, containers exit when the root process used to run the container exits.\ndocker run -d -t -p 801:80 loodse/demo-www\nDetaching from a running container Run a container. docker run -it --name counter loodse/counter It will create and run a new container with name counter from image loodse/counter and will print a a numbers in increasing fashion on screen. You can detach from this running container using CTRL-p CTRL-q key sequence.\nAttaching to running container You can use docker attach to attach. Spawn a new container using docker run -d -it --name counter1 loodse/counter. It will start a container in detached mode using -d flag. You can attach local standard input, output, and error streams to a running container using docker attach counter1.\nList containers You can list containers using docker ps The docker ps command only shows running containers by default. To see all containers, use the -a (or \u0026ndash;all) flag. docker ps -a\nStop a running container Start a new container using docker run -d -it --name counter loodse/counter You can stop a running container using docker stop counter\nKill a container Start a new container using docker run -d -it --name newcounter loodse/counter. You can kill a container using docker kill newcounter. The main process inside the container will be sent SIGKILL, or any signal specified with option \u0026ndash;signal.\n","permalink":"https://kadirkarakoc.com/posts/docker-notes/dn3/","summary":"Run container in foreground In foreground mode (by default when -d is not specified), docker run can start the process in the container and attach the console to the process' standard input, output, and standard error. It can even pretend to be a TTY (this is what most command line executables expect) and pass along signals. docker run -t -p 80:80 loodse/demo-www To stop it, press ^C.\nDetached container To start a container in detached mode, use -d=true or just -d option.","title":"Docker[3] | Interacting with Containers"},{"content":"Downloading image In this scenario you will bring up your very first container.\nTo create a container you need image which will be the container created from. Images are usually hosted somewhere in an accessible location called Registry.\nIt is a single place to manage Docker images. Users can create account and push their own images to registry.\nUse following command to search our desired image in registry. docker search loodse You will get list of images belongs to a user loodse.\nNow we know that our desired image exists in registry, we need to pull it to our local system to create containers of it.\nExecute docker pull loodse/demo-www. docker pull command downloads image from docker hub (which serves as a default registry for docker installation).\nYou can see list of downloaded images using docker images.\nYou can see loodse/demo-www entry there.\nCreating a container Now we have image downloaded and ready to use, we can create container using docker run -d loodse/demo-www. The -d flag instructs docker to create container and run it in background.\nYou can see list of running containers using docker ps. You can see an entry with loodse/demo-www string in IMAGE column. To interact with container you need CONTAINER ID which you can grab from first column.\nInspect running container We can get details of running container using docker inspect command. You can use that command like docker inspect \u0026lt;CONTAINER ID\u0026gt;.\nIt gives you whole lot of information about running container including IP, MacAddress, Hostname etc.\nList container List all running container.\ndocker ps\nThe docker ps command only shows running containers by default. To see all containers, use the -a (or \u0026ndash;all) flag:\ndocker ps -a\nLet’s start a second webserver.\ndocker run -t -p 8080:80 loodse/demo-www\nWith docker ps you see now two running containers.\nUse the second terminal: docker ps -a\nTerminate running container Stop the started container. The main process inside the container will receive SIGTERM, and after a grace period, SIGKILL. Use the second terminal: docker stop --time 5 \u0026lt;yourContainerId\u0026gt;\nYou can also restart your container, try:\ndocker restart \u0026lt;yourContainerId\u0026gt;\nIf you have e.g. an hanging container, it\u0026rsquo;s possible to send the SIGKILL signal directly. Try\ndocker kill \u0026lt;yourContainerId\u0026gt;\n","permalink":"https://kadirkarakoc.com/posts/docker-notes/dn2/","summary":"Downloading image In this scenario you will bring up your very first container.\nTo create a container you need image which will be the container created from. Images are usually hosted somewhere in an accessible location called Registry.\nIt is a single place to manage Docker images. Users can create account and push their own images to registry.\nUse following command to search our desired image in registry. docker search loodse You will get list of images belongs to a user loodse.","title":"Docker[2] | Run a Web App with Docker"},{"content":"Hello World In your Docker environment, simply run this command:\ndocker run alpine echo hello world\n•\trun a command in a new container •\talpine is one of the smallest Linux systems •\techo hello world is the command which is executed\nRun an Apache in a Container For interactive processes (like a shell), you must use docker run with -i -t together in order to allocate a tty for the container process. -i -t is often written -it.\nTo expose a container\u0026rsquo;s internal port, you can start the container with the -P or -p flag.\nThe exposed port is accessible on the host and the ports are available to any client that can reach the host.\nNow start a new container to install Apache trough the package manager - execute: docker run -it -p 80:80 ubuntu\nNow, let\u0026rsquo;s install it:\napt-get update \u0026amp;\u0026amp; apt-get install -y apache2\nStart the Apache:\napache2ctl -DFOREGROUND\nTest access to website, got to: http://localhost.com:80\nStop the Container Exit the process with (E.g. with ^C) as you normally would do: echo \u0026ldquo;Send Ctrl+C to Terminal\u0026rdquo;\nExit the shell with ^D or type exit. The container is stopped but it still exists on disk. You can take a look: docker ps -a\nTo delete all running and stopped container execute:\ndocker rm $(docker ps -aq)\nCheck if the containers get deleted:\ndocker ps -a\n","permalink":"https://kadirkarakoc.com/posts/docker-notes/dn1/","summary":"Hello World In your Docker environment, simply run this command:\ndocker run alpine echo hello world\n•\trun a command in a new container •\talpine is one of the smallest Linux systems •\techo hello world is the command which is executed\nRun an Apache in a Container For interactive processes (like a shell), you must use docker run with -i -t together in order to allocate a tty for the container process.","title":"Docker[1] | Run First Container"},{"content":"What is Docker? Docker is a containerization platform developed by a company called Docker Inc. It provides a runtime environment to run containers and interact with them. Docker uses some technologies like CGroups, Namespaces, etc to create an isolated containers.\nWhat is Container? A container is a lightweight, standalone package that encapsulates application code and all of its dependencies so the application can run in any environment. Containers are considered as lightweight virtualization technology. They are created from a container image.\nWhat is Container Image? A container image is a readonly, static file that includes executable code. It can be roughly considered as similar to template that is used to create something concrete that runs, which in our case if containers. Containers are created from container images. Image contains various layers which serves as a base for upper layers.\nWhy We Should Use Docker?  Deliver More Software In Short Time Docker users deliver apps on average 7x more often than non-Docker users. Docker allows you to deliver isolated services as often as needed. Standardize Operations Small containerized apps make it easy to deploy, identify issues, and rollback for fixes. Carry Seamlessly Docker-based applications can be seamlessly migrated from local development machines to production deployments on AWS. Save Docker containers improve your usage and save money by making it easy for you to run more code on each server.  How Can I install Docker? Follow steps given below to install Docker.\n Update the apt package index.\nsudo apt-get update Install packages to allow apt to use repository over HTTPS.\nsudo apt-get install apt-transport-https ca-certificates curl gnupg-agent software-properties-common Add Docker\u0026rsquo;s official GPG key.\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - Setup a stable repository.\nsudo add-apt-repository \u0026quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\u0026quot; Update the apt package index.\nsudo apt-get update Install the latest version of Docker CE and containerd.\nsudo apt-get install docker-ce=18.06.1~ce~3-0~ubuntu Validate Docker Installation with using the following command.\ndocker -v  ","permalink":"https://kadirkarakoc.com/posts/docker-notes/dn0/","summary":"What is Docker? Docker is a containerization platform developed by a company called Docker Inc. It provides a runtime environment to run containers and interact with them. Docker uses some technologies like CGroups, Namespaces, etc to create an isolated containers.\nWhat is Container? A container is a lightweight, standalone package that encapsulates application code and all of its dependencies so the application can run in any environment. Containers are considered as lightweight virtualization technology.","title":"Docker[0] | 'What is it?'"},{"content":"FileSystem Hiyerarşi    Klasör Ne için kullanılır?     /root the root user home directory   /bin commands, such as ls, pwd etc.   /boot boot stuff for the Linux kernel   /dev device files, for example harddrives, mice, keyboards, terminals, modems etc.   /etc all system configuration files   /home all users home directories   /lib shared libraries for programs and commands   /lib64 same as above, but for 64-bit programs   /lost+found files that are lost due to harddrive corruption   /mnt a directory used as a mount point for extra drives etc.   /opt often used for commercial third party softare   /proc system information and runtime stuff   /run PID-files for daemons etc.   /sbin commands for system administration, for example ifconfig   /srv often used by commercial third party server software   /tmp temporary files used by both programs, daemons and users   /usr important system files, programs, libraries, documentation etc.   /var system log files, printer spool directory, mail directories and other various stuff    ","permalink":"https://kadirkarakoc.com/posts/gnulinux/gln2/","summary":"FileSystem Hiyerarşi    Klasör Ne için kullanılır?     /root the root user home directory   /bin commands, such as ls, pwd etc.   /boot boot stuff for the Linux kernel   /dev device files, for example harddrives, mice, keyboards, terminals, modems etc.   /etc all system configuration files   /home all users home directories   /lib shared libraries for programs and commands   /lib64 same as above, but for 64-bit programs   /lost+found files that are lost due to harddrive corruption   /mnt a directory used as a mount point for extra drives etc.","title":"GNU/Linux[2] | 'What is it?'"},{"content":"Şimdi biraz sistemimizi tanıyalım.\nSistemimize login olduktan sonra ilk komutumuz olan uptime\u0026lsquo;ı çalıştıralım. Örnek olarak komut çıktısı aşağıdaki gibi;\n23:44:16 up 47 days, 10:02, 3 users, load average: 1,32, 1,15, 1,18 İlk kısım güncel saati, ikinci kısım sistemimizin ne kadar süredir açık ve komut almaya hazır bir şekilde beklediğini, üçüncü kısımda kaç kullanıcının bu sisteme bağlı olduğunu ve son kısımda da ilk kısmı son dakikanın ikinci kısmı son 5 dakikanın üçüncü kısım ise son 15 dakikanın ortalaması olacak şekilde sistemin ortalama (1 Process / 1 CPU Core = 1 Load average) yük bilgisini gösterir. Evet sistemimize ait tüm bu bilgileri kısa bir komut sayesinde öğrenebildik. Kullanımı oldukça güzel öyle değil mi?\nŞimdi başlangıç düzeyinde birkaç komut kullanalım.\nwho Şu anda sistemde oturum açmış olan kullanıcılar hakkında bilgi almak için yazın.\ntop Top komutu sistemde şu anda çalışan işlemler hakkında bilgi verir.\nfree Sisteminizde, bellekte ne kadar kullanılabilir ne kadar kullanılan memory olup olmadığını insan tarafından okunabilir (human readable) biçimde bilgi almak için free -m yazın. -M parametresi megabayt anlamına gelir.\nBilgileri gigabayt cinsinden görüntülemek için ise free -g komutunu da kullanabilirsiniz.\nLinux Sistemlerde Yardım Almak | man Sayfaları Man sayfaları Linux içerisine yerleşik olarak gelen, her komut için bulunan ve içerisinde komutların detaylı olarak parametreleriyle birlikte nasıl kullanılabileceğini belirten manual sayfalarıdır. Örnek olarak free komutunun ne işe yaradığına bakalım. Bunun için man free yazmak yeterli. Her defasında bir satır aşağıya kaydırmak için Enter tuşuna basarak, tek seferde bir tam sayfa ilerlemek için ise spacebar tuşuna basarak ilerileyebilirsiniz. Bunun yanı sıra yön okları da size yardımcı olacaktır.\nDaha sonrasında göreceğimiz vim adında bir editörde de kullanacağımız gibi, burada da arama işlemi için / kullanabiliriz. / sonrasında aranacak kelimeyi direkt olarak yazdığımızda sayfanın başından itibaren aradığımız kelime ya da harf grubunu işaretli bir biçimde gösterecektir. Bir sonraki eşleşmeye gitmek için n (next) tuşunu kullanın. Çıkmak için ise q (quit) tuşunu kullanın.\nEğer bir komutun basitçe neler yaptığını ya da nasıl kullanıldığını görmek istersek de -h (h for help) parametresi hemen hemen her komutda bulunur. Örnek olarak uptime komutunun basitçe ne yaptığını görmek için uptime -h komutunu deneyelim.\n$ uptime -h Usage: uptime [options] Options: -p, --pretty show uptime in pretty format -h, --help display this help and exit -s, --since system up since -V, --version output version information and exit For more details see uptime(1) Örnek olarak -p (p for pretty) parametresi sistemin up olduğu zamanı biraz daha okunaklı halde çıktısını görebiliriz.\n$ uptime -p up 1 week, 4 days, 7 hours, 29 minutes Linux Sistemlerde Yardım almak | TAB Tuşu Tab tuşu ilerleyen zamanlar en büyük yardımcımız olmaya adaydır. Bu tuş da bir komutu yazmaya başladınız ve tuşu kullandığınız andan itibaren komutları tamamlamaya yardımcı olur. Ya da komutun tamamını yazmak istemediğinizde bu tuş yardımınıza koşar. Örnek olarak l harfiyle başlayan kullanabileceğimiz komutları listelemek istiyorsak da l harfini yazdıktan sonra tab tuşuna iki kez bastığımızda bize bu listeyi verecektir.\n","permalink":"https://kadirkarakoc.com/posts/gnulinux/gln1/","summary":"Şimdi biraz sistemimizi tanıyalım.\nSistemimize login olduktan sonra ilk komutumuz olan uptime\u0026lsquo;ı çalıştıralım. Örnek olarak komut çıktısı aşağıdaki gibi;\n23:44:16 up 47 days, 10:02, 3 users, load average: 1,32, 1,15, 1,18 İlk kısım güncel saati, ikinci kısım sistemimizin ne kadar süredir açık ve komut almaya hazır bir şekilde beklediğini, üçüncü kısımda kaç kullanıcının bu sisteme bağlı olduğunu ve son kısımda da ilk kısmı son dakikanın ikinci kısmı son 5 dakikanın üçüncü kısım ise son 15 dakikanın ortalaması olacak şekilde sistemin ortalama (1 Process / 1 CPU Core = 1 Load average) yük bilgisini gösterir.","title":"GNU/Linux[1] | Nedir? Part-II"},{"content":"Bu yazı serisinde GNU/Linux hakkında öğrendiklerimi yazıyorum.\nLinux Kernel, işletim sisteminin beynidir. Linux Kernel ilk kez 1991 yılında Linus Torvalds tarafından piyasaya sürüldü. Ama birlikte çalışacak programlar için herhangi bir aracımız yoksa, sadece bir kernel bir işinize yaramayacaktır. GNU Tools işte tam bu noktada devreye giriyor. GNU Tools, bash shell gibi araçlar, make ve GNU Compiler gibi çeşitli programlamaya yardımcı programlar ve daha birçok araç ve programdan oluşuyor. GNU Tools, 1984 yılında Richard Matthew Stallman tarafından başlatıldı. Birlikte, linux kernel ve GNU Tools, GNU / Linux olarak adlandırdığımız şeyi oluşturdular.\nGünümüzde Ubuntu, Debian, CentOS, Slackware, Suse ve Fedora gibi birçok farklı Linux dağıtımı mevcut. Fakat Linux dağıtımı nedir? Aslında diğer yazılım araçlarıyla birlikte paketleniyor. Bunlar, Firefox Web Tarayıcısı, programlama yazılımları ve video düzenleme programları gibi tipik üçüncü taraf yazılımlarıdır.\nFarklı dağıtımlar ayrıca kendi yazılım yönetim sistemleri veya yazılım paketleme sistemi ile birlikte gelir. Bu, üçüncü taraf yazılımları yüklemek, güncellemek ve yönetmek için kullanılan bir programdır. Buradaki iki büyük oyuncu Debian projesinden APT ve RedHat\u0026rsquo;tan yum.\nBütün bunların yanı sıra, tüm linux dağıtımları birbirine oldukça benzerdir. Bunlardan birini öğrenirseniz, örnek olarak Ubuntu, CentOS kullanmak konusunda da çok fazla zorlanmayacaksınız. Aralarındaki en büyük fark yazılım paketleme sistemleridir. Öte yandan GNU Tools hepsinde aynıdır. Dosya sistemleri ve yaklaşık yüzde 80 ya da 90 kadar paketlenmiş yazılımları da aynıdır.\nAynı zamanda yazılımların versiyonlaması konusunda da farklılık görebiliriz. Örnek olarak Ubuntu dağıtımda görece daha güncel third party yazılımlar bulunurken, CentOS bu uygulamaların daha eski versiyonlarını kullanır. Ayrıca Kernel versiyonu da CentOS\u0026rsquo;da daha eskilerdedir. Bunu kötü bir manada ele almamak gerekir. CentOS bunu daha stabil bir sistem sunabilmek için bilinçli olarak yapmaktadır.\nDağıtım seçimi iki ana konu üzerinde şekillenir. Bunlardan birincisi paketleme sistemi konusundaki kişisel tercihler ve ikincisi ise sistemin stabil olması durumudur. Burada doğru ya da yanlış bulunmamaktadır. Kişisel tercihlerimiz bunu belirler. Hepsini denemenizi ve hoşunuza gidenle yolunuza devam etmenizi tavsiye ederim. Linux\u0026rsquo;u böylesine güzel yapan da herkesin kendine göre bir şeyler bulabilir oluşudur.\n","permalink":"https://kadirkarakoc.com/posts/gnulinux/gln0/","summary":"Bu yazı serisinde GNU/Linux hakkında öğrendiklerimi yazıyorum.\nLinux Kernel, işletim sisteminin beynidir. Linux Kernel ilk kez 1991 yılında Linus Torvalds tarafından piyasaya sürüldü. Ama birlikte çalışacak programlar için herhangi bir aracımız yoksa, sadece bir kernel bir işinize yaramayacaktır. GNU Tools işte tam bu noktada devreye giriyor. GNU Tools, bash shell gibi araçlar, make ve GNU Compiler gibi çeşitli programlamaya yardımcı programlar ve daha birçok araç ve programdan oluşuyor. GNU Tools, 1984 yılında Richard Matthew Stallman tarafından başlatıldı.","title":"GNU/Linux[0] | Nedir? Part-I"}]